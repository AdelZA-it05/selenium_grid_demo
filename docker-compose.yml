## Стек Docker Compose для запуска Selenoid, Selenoid UI и тестов
##
## Как это работает:
## - Selenoid (порт 4444) поднимает сессии, создавая под каждую тестовую сессию
##   отдельный контейнер с браузером согласно конфигу browsers.json.
## - Selenoid UI (порт 8080) показывает активные/прошедшие сессии, позволяет скачивать видео.
## - tests — контейнер‑тест‑раннер, который подключается к Selenoid по внутреннему DNS.
##
## Важно: на Apple Silicon (arm64) образы Selenoid/браузеров чаще под amd64, поэтому
## используется эмуляция (qemu). Это нормально, но может работать медленнее.
services:
  selenoid:
    # Основной хаб Selenoid (динамически запускает контейнеры с браузерами)
    image: aerokube/selenoid:latest-release
    # Принудительно amd64: официальные образы Selenoid собраны под amd64; на Apple Silicon используется эмуляция
    platform: linux/amd64
    container_name: selenoid
    # Аргументы запуска Selenoid (список, чтобы избежать проблем парсинга)
    command: [
      "-conf", "/etc/selenoid/browsers.json",
      "-video-output-dir", "/opt/selenoid/video",
      "-log-output-dir", "/opt/selenoid/logs",
      "-capture-driver-logs",
      "-service-startup-timeout", "2m",
      "-container-network", "selenoid_grid"
    ]
    ports:
      # Публикуем порт Selenoid hub
      - "4444:4444"
    volumes:
      # Доступ к Docker сокету для управления контейнерами браузеров
      - /var/run/docker.sock:/var/run/docker.sock
      # Подключаем конфигурацию браузеров
      - ./selenoid/browsers.json:/etc/selenoid/browsers.json:ro
      # Пробрасываем каталоги видео и логов на хост
      - ./selenoid/video:/opt/selenoid/video
      - ./selenoid/logs:/opt/selenoid/logs
    environment:
      # Важно для macOS: путь к видео должен быть расшарен в Docker Desktop (Settings → Resources → File sharing)
      # Параметризуем в CI: OVERRIDE_VIDEO_OUTPUT_DIR=$GITHUB_WORKSPACE/selenoid/video
      - OVERRIDE_VIDEO_OUTPUT_DIR=${OVERRIDE_VIDEO_OUTPUT_DIR:-/Users/sergeytsarev/selenium-selenoid-demo/selenoid/video}
    networks:
      - grid
    healthcheck:
      # Проверяем, что хаб Selenoid отвечает на /status (wget есть в образе)
      test: ["CMD-SHELL", "wget -qO- http://localhost:4444/status >/dev/null || exit 1"]
      interval: 2s
      timeout: 1s
      retries: 60
      start_period: 5s

  selenoid-ui:
    # Веб‑интерфейс для наблюдения за сессиями, скачивания видео и просмотра логов
    image: aerokube/selenoid-ui:latest-release
    platform: linux/amd64
    container_name: selenoid-ui
    depends_on:
      - selenoid
    ports:
      # Публикуем UI
      - "8080:8080"
    command: ["--selenoid-uri", "http://selenoid:4444"]
    networks:
      - grid

  tests:
    # Контейнер тест‑раннера с pytest + selenium
    build:
      context: .
      dockerfile: Dockerfile.tests
    environment:
      # Подключение к Selenoid по DNS‑имени внутри сети compose
      - SELENOID_URL=http://selenoid:4444/wd/hub
      # Имя используется для удобного имени видеофайла и отображается в UI
      - TEST_NAME=test_google
    volumes:
      # Монтируем проект для запуска исходников без пересборки образа
      - ./:/app:rw
    working_dir: /app
    # Ждать готовности Selenoid через healthcheck
    depends_on:
      selenoid:
        condition: service_healthy
    # Используем CMD из Dockerfile.tests (pytest -q)
    networks:
      - grid

volumes: {}

## Общая пользовательская сеть для предсказуемого DNS и связи
## Все сервисы находятся в одной сети, чтобы:
## - tests мог резолвить имя selenoid
## - selenoid создавал браузерные контейнеры в этой же сети (см. -container-network)
networks:
  grid:
    name: selenoid_grid


